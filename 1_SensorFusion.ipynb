{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d92630ed-fa5f-4e17-9495-a35f020390bf",
   "metadata": {},
   "source": [
    "# Kalman Filtering\n",
    "\n",
    "В цьому завданні, пропонується імплементувати лінійний фільтр Калмана і застосувати його для поєднання показників сенсорів.\n",
    "\n",
    "Використання підходів на базі Баєсівської фільтрації є стандартом в задачах такого типу. Наприклад:\n",
    "\n",
    "- GNSS (GPS). Поєднання 5-12 сигналів супутників для уточнення позиції приймача. Див [laika](https://github.com/commaai/laika), а саме [ноутбук](https://github.com/commaai/laika/blob/master/examples/Compute_station_pos.ipynb)\n",
    "- Поєднання сенсорів одометрії. Наприклад [GPS та IMU](https://www.youtube.com/watch?v=hN8dL55rP5I) для уточнення положення приймача та локалізації.\n",
    "- Багато інших. Просто гугліть \"Sensor fusion\" :)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436c088d-4d59-43c6-be0a-33f768872039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "randn = np.random.randn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95235a7-01bb-4609-b8fa-185b23db969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max = 12\n",
    "t_15Hz = np.linspace(start=0, stop=t_max, num=t_max * 15)\n",
    "t_2Hz = np.linspace(start=0, stop=t_max, num=t_max * 2)\n",
    "\n",
    "def f1(t):\n",
    "    return np.sin(t) / 2 + t / 2 * np.cos(t)\n",
    "\n",
    "def my_signal(t, noise_std=0.0):\n",
    "    signal_vals_1 = f1(t)\n",
    "    signal_vals_2 = f1(6.5)\n",
    "    signal_vals =  signal_vals_1 * (t < 6.5) + (t >= 6.5) * signal_vals_2 \n",
    "    return signal_vals + randn(*t.shape)*noise_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84cbe8b-ebcb-4b9f-b7c7-36e1137a359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1(6.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c137fbb3-fc2b-4e8d-804d-886049bdf7fb",
   "metadata": {},
   "source": [
    "# Сигнал\n",
    "Спочатку розглянемо оригінальний сигнал.\n",
    "$$ f(t) = \\begin{cases} \n",
    "0.5 \\sin(t) + 0.5 t \\cos(t) & t < 6.5 \\\\\n",
    "3.281... & t \\ge 6.5\n",
    "\\end{cases}\n",
    "$$\n",
    "Та його зашумлені версії, які й спостерігають наші два сенсори\n",
    "$$ \\xi_1(t) = \\mathcal{N} (f(t), \\sigma_1) = f(t) + \\mathcal{N} (0, 1) \\sigma_1\n",
    "$$\n",
    "\n",
    "$$ \\xi_2(t) = \\mathcal{N} (f(t), \\sigma_2) = f(t) + \\mathcal{N} (0, 1) \\sigma_2\n",
    "$$\n",
    "\n",
    "$$ \\sigma_1 = 1.5, \\sigma_2 = 0.1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefd0631-259d-4afe-ac2f-7e9a4128a203",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "plt.plot(t_15Hz, my_signal(t_15Hz), label=\"$f(t)$\")\n",
    "plt.plot(t_15Hz, my_signal(t_15Hz, noise_std=2.0), label=\"$\\\\xi_1(t)$\")\n",
    "plt.scatter(t_2Hz, my_signal(t_2Hz, noise_std=0.1), label=\"$\\\\xi_2(t)$\")\n",
    "plt.xlabel(\"time, $t$\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb13410-674f-4b2a-be94-96c8b2c640a2",
   "metadata": {},
   "source": [
    "Як бачите,\n",
    "\n",
    "- перший сенсор $\\xi_1(t)$ є доволі **шумним**, проте він видає свої показники з частотою **15Hz** (15 показань на секунду)\n",
    "- другий сенсор $\\xi_2(t)$ є майже **чистим**, проте він видає свої показники з частотою **всього 2Hz** (2 показання на секунду)\n",
    "\n",
    "В ідеалі, ми б хотіли використати інформацію з обох сенсорів для відновлення сигналу. Але спочатку...\n",
    "\n",
    "# Фільтр Калмана для зменшення шуму сигналу\n",
    "\n",
    "Нагадаю, що рівняння системи, з якою працює лінійний КФ формулюється наступним чином:\n",
    "\n",
    "$$ x_k = \\textbf{F} x_{k-1} + \\mathcal{N} (0, \\textbf{Q}) $$\n",
    "$$ z_k = \\textbf{H} x_{k} + \\mathcal{N} (0, \\textbf{R}) $$\n",
    "\n",
    "Звичайно, при наявності двох сенсорів, у нас буде два типи спостережень із різними дисперсіями. Але спочатку розглянемо лише один $ R = 1.5^2 $. Не будемо навіть розглядати динаміку. Скажемо, що $\\textbf{F} = \\textbf{I}$. Більше того, оскільки стан включає в себе лише один скаляр, то всі розмірності в рівняннях будуть одиничними:\n",
    "\n",
    "$$ x_k = x_{k-1} + \\mathcal{N} (0, Q) $$\n",
    "$$ z_k = x_{k} + \\mathcal{N} (0, 1.5^2) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd4d431-4277-412f-b951-506c962f6b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Початкова матриця коваріації визначається звичайним підбором. Припустимо такі значення\n",
    "P = np.array([[1.0]])\n",
    "# Для коваріації похибки моделі також визначаємо значення підбором.\n",
    "Q = np.array([[1.0]])\n",
    "\n",
    "H = np.array([[1.0]])\n",
    "R1 = np.array([[1.5**2]])\n",
    "R2 = np.array([[0.1**2]])  # буде потрібно далі\n",
    "\n",
    "# Зверніть увагу, F - це функція від dt. Оскільки динаміка відсутня, ця функція - константа. \n",
    "# Цікаво спробувати додати динаміку і подивитись чи зміняться результати!\n",
    "get_F = lambda dt: np.array([[1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cf9d66-65d8-485e-9860-3a8f4493f585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# Виконайте вказівки в lib/my_kalman.py\n",
    "# ---------------------------------------\n",
    "from lib.my_kalman import update, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d332f3a6-fbca-4199-a1fc-c80c47e618fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конструюємо сигнал на сенсорі (1).\n",
    "z_15Hz = my_signal(t_15Hz, noise_std=1.5)\n",
    "t = t_15Hz[0]\n",
    "x = np.array([z_15Hz[0]])\n",
    "\n",
    "# Використовуємо фільтр Калмана (predict та update).\n",
    "filtered_signal = np.empty(t_15Hz.shape[0])\n",
    "filtered_signal_sigma = np.empty(t_15Hz.shape[0])\n",
    "\n",
    "filtered_signal[0] = x[0]\n",
    "filtered_signal_sigma[0] = P[0][0]\n",
    "\n",
    "for i in range(1, t_15Hz.shape[0]):\n",
    "    dt = t_15Hz[i] - t\n",
    "    t = t_15Hz[i]\n",
    "    z = z_15Hz[i]\n",
    "    # КФ\n",
    "    x_next, P_next = predict(x, P, get_F(dt), Q=Q)\n",
    "    x, P = update(x_next, P_next, z, R1, H)\n",
    "    \n",
    "    filtered_signal[i] = x[0]\n",
    "    filtered_signal_sigma[i] = P[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c207aa5-36e5-43cc-8d05-7d0be4e6439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "plt.title(\"Фільтрація першого сенсора\")\n",
    "plt.plot(t_15Hz, my_signal(t_15Hz), label=\"$f(t)$\")\n",
    "plt.plot(t_15Hz, z_15Hz, label=\"$\\\\xi_1(t)$\")\n",
    "plt.plot(t_15Hz, filtered_signal, label=\"після фільтрації\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd66ba9-7ad8-403a-9ad2-def669dfde49",
   "metadata": {},
   "source": [
    "Але також було б цікаво подивитись на трохи іншу візуалізацію.\n",
    "\n",
    "Нагадаю, що $\\xi_1(t)$ має дисперсію і є імовірнісним сигналом. Вище, ми розглядали лише його реалізацію. То ж давайте порівняємо параметри випадкових процесів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d67c91-10ab-4d3d-88f2-4fe24b286e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "plt.title(\"Фільтрація першого сенсора - процеси\")\n",
    "f_t = my_signal(t_15Hz)\n",
    "sigma_t = 1.5\n",
    "plt.plot(t_15Hz, f_t, label=\"$f(t)$\")\n",
    "plt.fill_between(t_15Hz, f_t - sigma_t, f_t + sigma_t, alpha=0.5)\n",
    "plt.plot(t_15Hz, filtered_signal, label=\"після фільтрації\")\n",
    "plt.fill_between(t_15Hz, filtered_signal - filtered_signal_sigma, filtered_signal + filtered_signal_sigma, alpha=0.5)\n",
    "# plt.fill_between(t_10Hz, f_t - filtered_signal_sigma, f_t + filtered_signal_sigma, alpha=0.5)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e981eb-cff2-4521-9e58-d3d2d5d2b5f8",
   "metadata": {},
   "source": [
    "## Візуалізація анімації процесу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8e748b-9623-4538-af73-8223831b9f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm \n",
    "x = np.linspace(start=-8, stop=8, num=100)\n",
    "f_t = my_signal(t_15Hz)\n",
    "sigma_t = 1.5\n",
    "\n",
    "fig, ax = plt.subplots(dpi=200)\n",
    "ax.set_xlim(-8, 8)\n",
    "ax.set_ylim(0, 1.0)\n",
    "filtered_signal_plot, = ax.plot([],[], label=\"KF - $\\mathcal{N}(x_t, P_t)$\")\n",
    "xi1_plot, = ax.plot([],[], label=\"$\\\\xi_1$ - $\\mathcal{N}(f(t), 1.5^2)$\")\n",
    "xi1_z_plot, = ax.plot([],[], label=\"$\\\\xi_1$ - спостереження\")\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set_xlabel(\"значення сигналу\")\n",
    "ax.set_ylabel(\"'Імовірність'\")\n",
    "\n",
    "def animate(i):\n",
    "    loc = filtered_signal[i]\n",
    "    scale = filtered_signal_sigma[i]\n",
    "    filtered_signal_plot.set_data(x, norm.pdf(x, loc=loc, scale=scale))\n",
    "    xi1_plot.set_data(x, norm.pdf(x, loc=f_t[i], scale=sigma_t))\n",
    "    xi1_z_plot.set_data([z_15Hz[i], z_15Hz[i]], [0.0, 1.0])\n",
    "\n",
    "import matplotlib.animation\n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(t_15Hz))\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa4401d-abea-4982-8a44-260d2a984c48",
   "metadata": {},
   "source": [
    "# Але чим це відрізняється від інших методів згладжування?\n",
    "\n",
    "Упевнений, що багато з вас знайомі із методами ковзних середніх та іншими методами згладжування. Може постати питання, чим вони відрізняються від КФ?\n",
    "\n",
    "Окрім того, що згладжування це лише одна підзадача, яку вирішує КФ, існує глибокий зв'язок між методами відновлення стану (до яких відноситься КФ) і іншими методами часових рядів.\n",
    "\n",
    "\n",
    "\n",
    "Якщо взяти Експоненційне ковзне середнє, то [зв'язок](https://stats.stackexchange.com/a/16474) полягає в тому що КФ реалізує достатньо схожу схему згладжування, лиш параметр змінюється відповідно до апріорних знань (R, Q, x0, P0, etc.) та даних часового ряду.\n",
    "\n",
    "Ось приклад:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96684992-01f3-4edd-bf9f-da063f594c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.ewma import ewma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a8353-206c-4c56-bd6a-3d3765509674",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "plt.title(\"Фільтрація першого сенсора - KF vs EWMA\")\n",
    "ewma_signal = ewma_vectorized(z_15Hz, alpha=0.991)\n",
    "plt.plot(t_15Hz, my_signal(t_15Hz), label=\"$f(t)$\")\n",
    "plt.plot(t_15Hz, ewma_signal, label=\"Експоненційне ковзне середнє\")\n",
    "plt.plot(t_15Hz, filtered_signal, label=\"filtered\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84ea4a8-8626-4a88-8297-0c186c349217",
   "metadata": {},
   "source": [
    "# Два сенсори!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b155a76-5585-4b78-81fa-adda44c22214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(arr1, arr2):\n",
    "    ''' Поєднуємо потоки спостережень. '''\n",
    "    arr_merged = []\n",
    "    from_merged = []\n",
    "    idx_merged = []\n",
    "    i1 = 0\n",
    "    i2 = 0\n",
    "    while i1 < len(arr1) or i2 < len(arr2):\n",
    "        if i1 < len(arr1) and (i2 >= len(arr2) or arr1[i1] < arr2[i2]):\n",
    "            arr_merged.append(arr1[i1])\n",
    "            from_merged.append(0)\n",
    "            idx_merged.append(i1)\n",
    "            i1 += 1\n",
    "        else:\n",
    "            arr_merged.append(arr2[i2])\n",
    "            from_merged.append(1)\n",
    "            idx_merged.append(i2)\n",
    "            i2 += 1\n",
    "    return np.array(arr_merged), np.array(from_merged), np.array(idx_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0214a162-46b1-4e52-99ef-1058b049fe84",
   "metadata": {},
   "source": [
    "Все те саме, але у нас тепер два види спостережень із різними рівнями шуму спостережень (measurement noise, R).\n",
    "Обʼєднуємо ці спостереження банально оновлюючи КФ обома спостереженнями, але із різними параметрами R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3728250c-de3e-4e6b-83e1-2edbf6e076b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конструюємо сигнал на сенсорі (1).\n",
    "z1_15Hz = z_15Hz\n",
    "z2_2Hz = my_signal(t_2Hz, noise_std=0.1)\n",
    "t = t_15Hz[0]\n",
    "x = np.array([z2_2Hz[0]])\n",
    "\n",
    "t_merged, from_merged, idx_merged = merge(t_15Hz, t_2Hz)\n",
    "\n",
    "# Використовуємо фільтр Калмана (predict та update).\n",
    "fused_signal = np.empty(t_merged.shape[0])\n",
    "fused_signal[0] = x[0]\n",
    "\n",
    "for i in range(0, t_merged.shape[0]):\n",
    "    dt = t_merged[i] - t\n",
    "    t = t_merged[i]\n",
    "    z = [z1_15Hz, z2_2Hz][from_merged[i]][idx_merged[i]]\n",
    "    R = [R1, R2][from_merged[i]]\n",
    "\n",
    "    # КФ\n",
    "    x_next, P_next = predict(x, P, get_F(dt), Q=Q)\n",
    "    x, P = update(x_next, P_next, z, R, H)\n",
    "    \n",
    "    fused_signal[i] = x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727513c8-b435-40cc-bfa4-0c77bfddae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "plt.title(\"Фільтрація двох сенсорів\")\n",
    "plt.plot(t_15Hz, my_signal(t_15Hz), label=\"$f(t)$\")\n",
    "plt.plot(t_15Hz, z1_15Hz, label=\"$\\\\xi_1(t)$\")\n",
    "plt.scatter(t_2Hz, z2_2Hz, label=\"$\\\\xi_2(t)$\")\n",
    "# plt.plot(t_15Hz, filtered_signal, label=\"після фільтрації\")\n",
    "plt.plot(t_merged, fused_signal, label=\"після фільтрації (2 сенсора)\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2d99ee-37d5-4e9c-a18c-c90e6af05667",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "plt.title(\"Фільтрація двох сенсорів (порівняння)\")\n",
    "plt.plot(t_15Hz, my_signal(t_15Hz), label=\"$f(t)$\")\n",
    "plt.plot(t_15Hz, filtered_signal, label=\"після фільтрації\")\n",
    "plt.plot(t_merged, fused_signal, label=\"після фільтрації (2 сенсора)\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db96269c-5b7e-4018-b06c-2b2287b9bb36",
   "metadata": {},
   "source": [
    "Як бачите, об'єднана версія майже завжди лежить між першою версією та оригінальним сигналом, тобто є завжди більш точною.\n",
    "\n",
    "Звичайно, коли маємо одновимірний сигнал, перевага не настільки величезна, плюс ми знаємо параметри шумів. В реальності обʼєднання сенсорів - трюк дуже важливий, який часто є необхідним для мінімально допустимої якості обробки сенсорів!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16147b9-0332-47df-b52a-6658f8ef1270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
